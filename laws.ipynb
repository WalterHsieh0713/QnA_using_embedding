{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtSCdGEN4_Pk",
        "outputId": "f4613b18-53f4-4bfa-e5a8-66c99953c050"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully retrieved and saved to civil_laws.csv\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "url = \"https://law.moj.gov.tw/LawClass/LawAll.aspx?pcode=B0000001\"\n",
        "\n",
        "response = requests.get(url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find all law articles\n",
        "    law_articles = soup.find_all('div', {'class': 'law-article'})\n",
        "\n",
        "    with open('civil_laws.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "\n",
        "        for law_article in law_articles:\n",
        "            # Find the specific line within the law-article div\n",
        "            law_text = law_article.find('div', {'class': 'line-0000'}).text.strip()\n",
        "\n",
        "            # Write the law text to the CSV file\n",
        "            csv_writer.writerow([law_text])\n",
        "\n",
        "    print(\"Data successfully retrieved and saved to civil_laws.csv\")\n",
        "else:\n",
        "    print(\"Failed to retrieve data. Status code:\", response.status_code)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "url = \"https://law.moj.gov.tw/LawClass/LawAll.aspx?pcode=B0000001\"\n",
        "\n",
        "response = requests.get(url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find all law sections\n",
        "    law_sections = soup.find_all('div', {'class': 'law-reg-content'})\n",
        "\n",
        "    with open('civil_laws.csv', 'w', newline='', encoding='utf-8-sig') as csvfile:\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "\n",
        "        # Write header row\n",
        "        csv_writer.writerow(['Law Type', 'Section', 'Chapter', 'Law Number', 'Law Content'])\n",
        "\n",
        "        for section in law_sections:\n",
        "            # Extract section title\n",
        "            section_title = section.find('div', {'class': 'h3'}).text.strip()\n",
        "\n",
        "            # Extract chapter title and law information within the section\n",
        "            chapter_titles = section.find_all('div', {'class': 'h3 char-2'})\n",
        "            for chapter_title in chapter_titles:\n",
        "                chapter_title_text = chapter_title.text.strip()\n",
        "\n",
        "                # Extract law information within the chapter\n",
        "                law_rows = chapter_title.find_all_next('div', {'class': 'row'})\n",
        "                for law_row in law_rows:\n",
        "                    col_no_element = law_row.find('div', {'class': 'col-no'})\n",
        "                    law_number = col_no_element.text.strip() if col_no_element else \"N/A\"\n",
        "\n",
        "                    law_content_element = law_row.find('div', {'class': 'line-0000'})\n",
        "                    law_content = law_content_element.text.strip() if law_content_element else \"N/A\"\n",
        "\n",
        "                    # Write the data to the CSV file\n",
        "                    csv_writer.writerow(['民法', section_title, chapter_title_text, law_number, law_content])\n",
        "\n",
        "    print(\"Data successfully retrieved and saved to civil_laws.csv\")\n",
        "else:\n",
        "    print(\"Failed to retrieve data. Status code:\", response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYwOho8o8Aq6",
        "outputId": "4dc36dc8-26ca-417c-8703-7a0c8ddecac9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully retrieved and saved to civil_laws.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "# Define the URL for 刑法\n",
        "criminal_law_url = \"https://law.moj.gov.tw/LawClass/LawAll.aspx?pcode=C0000001\"\n",
        "\n",
        "response = requests.get(criminal_law_url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find all law sections\n",
        "    law_sections = soup.find_all('div', {'class': 'law-reg-content'})\n",
        "\n",
        "    with open('civil_laws.csv', 'a', newline='', encoding='utf-8-sig') as csvfile:\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "\n",
        "        # Iterate through 刑法 law sections\n",
        "        for section in law_sections:\n",
        "            # Extract chapter title and law information within the section\n",
        "            chapter_titles = section.find_all('div', {'class': 'h3 char-2'})\n",
        "            for chapter_title in chapter_titles:\n",
        "                chapter_title_text = chapter_title.text.strip()\n",
        "\n",
        "                # Extract law information within the chapter\n",
        "                law_rows = chapter_title.find_all_next('div', {'class': 'row'})\n",
        "                for law_row in law_rows:\n",
        "                    col_no_element = law_row.find('div', {'class': 'col-no'})\n",
        "                    law_number = col_no_element.text.strip() if col_no_element else \"N/A\"\n",
        "\n",
        "                    law_content_element = law_row.find('div', {'class': 'line-0000'})\n",
        "                    law_content = law_content_element.text.strip() if law_content_element else \"N/A\"\n",
        "\n",
        "                    # Write the data to the CSV file\n",
        "                    csv_writer.writerow(['刑法', '', chapter_title_text, law_number, law_content])\n",
        "\n",
        "    print(\"Data from 刑法 successfully added to civil_laws.csv\")\n",
        "else:\n",
        "    print(\"Failed to retrieve data. Status code:\", response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJCTCxZO907J",
        "outputId": "a64aa9c0-9153-4bbe-ac61-9104d08ddf8b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data from 刑法 successfully added to civil_laws.csv\n"
          ]
        }
      ]
    }
  ]
}